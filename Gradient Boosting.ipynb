{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4deef1",
   "metadata": {},
   "source": [
    "Gradient Boosting Model\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95632976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset from the .npz file\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Loading the data (NON-PCA)\n",
    "data = np.load(\"preprocessed_data.npz\")\n",
    "x_train_flat, y_train = data[\"x_train_flat\"], data[\"y_train\"]\n",
    "x_val_flat, y_val = data[\"x_val_flat\"], data[\"y_val\"]\n",
    "x_test_flat, y_test = data[\"x_test_flat\"], data[\"y_test\"]\n",
    "\n",
    "# Loading the data (PCA)\n",
    "data2 = np.load(\"preprocessed_data_pca95.npz\")\n",
    "x_train_pca95, y_train = data2[\"x_train_pca95\"], data2[\"y_train\"]\n",
    "x_val_pca95, y_val = data2[\"x_val_pca95\"], data2[\"y_val\"]\n",
    "x_test_pca95, y_test = data2[\"x_test_pca95\"], data2[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49257d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def train_evaluate_gb(x_train, y_train, x_val, y_val, x_test, y_test, learning_rate, n_estimators):\n",
    "    gb = GradientBoostingClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=3\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    gb.fit(x_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_train_pred = gb.predict(x_train)\n",
    "    y_val_pred = gb.predict(x_val)\n",
    "    y_test_pred = gb.predict(x_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    overfit_gap = train_acc - val_acc\n",
    "\n",
    "    print(f\"\\nGradient Boosting Model (lr={learning_rate}, estimators={n_estimators}):\")\n",
    "    print(f\"Train Accuracy:   {train_acc:.4f}\")\n",
    "    print(f\"Val Accuracy:     {val_acc:.4f}\")\n",
    "    print(f\"Test Accuracy:    {test_acc:.4f}\")\n",
    "    print(f\"Overfitting Gap:  {overfit_gap:.4f}\")\n",
    "    print(f\"Training Time:    {train_time:.2f} seconds\")\n",
    "\n",
    "    return {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfit_gap': overfit_gap,\n",
    "        'train_time': train_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54f58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Model (lr=0.05, estimators=100):\n",
      "Train Accuracy:   0.8765\n",
      "Val Accuracy:     0.8567\n",
      "Test Accuracy:    0.8597\n",
      "Overfitting Gap:  0.0198\n",
      "Training Time:    5410.18 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training 2 models on non-PCA dataset\n",
    "# Moderate Regularization\n",
    "gb1_results = train_evaluate_gb(x_train_flat, y_train, x_val_flat, y_val, x_test_flat, y_test, learning_rate=0.05, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c371ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Model (lr=0.01, estimators=300):\n",
      "Train Accuracy:   0.8554\n",
      "Val Accuracy:     0.8382\n",
      "Test Accuracy:    0.8457\n",
      "Overfitting Gap:  0.0172\n",
      "Training Time:    15756.04 seconds\n"
     ]
    }
   ],
   "source": [
    "# Higher Regularization\n",
    "gb2_results = train_evaluate_gb(x_train_flat, y_train, x_val_flat, y_val, x_test_flat, y_test, learning_rate=0.01, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defc9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Model (lr=0.05, estimators=100):\n",
      "Train Accuracy:   0.8476\n",
      "Val Accuracy:     0.8258\n",
      "Test Accuracy:    0.8258\n",
      "Overfitting Gap:  0.0218\n",
      "Training Time:    4806.85 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training the model on PCA Datasets\n",
    "gb3_results = train_evaluate_gb(x_train_pca95, y_train, x_val_pca95, y_val, x_test_pca95, y_test, learning_rate=0.05, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d678372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Model (lr=0.01, estimators=300):\n",
      "Train Accuracy:   0.8196\n",
      "Val Accuracy:     0.8027\n",
      "Test Accuracy:    0.8048\n",
      "Overfitting Gap:  0.0169\n",
      "Training Time:    19224.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now using different parameters\n",
    "gb4_results = train_evaluate_gb(x_train_pca95, y_train, x_val_pca95, y_val, x_test_pca95, y_test, learning_rate=0.01, n_estimators=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
